{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Studying Anagrams in the English Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = '/Users/mattjwilliams/Documents/LinkedInDataScience/PythonDataAnalysis/Exercise Files/Ch3/03_02/words'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(address, 'r') as f:\n",
    "    wordlist = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A\\n',\n",
       " 'a\\n',\n",
       " 'aa\\n',\n",
       " 'aal\\n',\n",
       " 'aalii\\n',\n",
       " 'aam\\n',\n",
       " 'Aani\\n',\n",
       " 'aardvark\\n',\n",
       " 'aardwolf\\n',\n",
       " 'Aaron\\n']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlist[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The worlist is read in, but it is desireable to remove the newline character at the end of each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235886"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordclean = [word.strip().lower() for word in wordlist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'a',\n",
       " 'aa',\n",
       " 'aal',\n",
       " 'aalii',\n",
       " 'aam',\n",
       " 'aani',\n",
       " 'aardvark',\n",
       " 'aardwolf',\n",
       " 'aaron']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordclean[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordunique = list(set(wordclean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bocca',\n",
       " 'cheapness',\n",
       " 'spurn',\n",
       " 'bakeshop',\n",
       " 'multinuclear',\n",
       " 'pouting',\n",
       " 'forcefully',\n",
       " 'counterpaly',\n",
       " 'sensationish',\n",
       " 'blaver']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordunique[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I converted to a set, which contains only unique instances of a list, in order to get rid of the duplicates. But doing so lost the alphabetical order of the original list, so we will need to sort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordunique.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'aa',\n",
       " 'aal',\n",
       " 'aalii',\n",
       " 'aam',\n",
       " 'aani',\n",
       " 'aardvark',\n",
       " 'aardwolf',\n",
       " 'aaron',\n",
       " 'aaronic']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordunique[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This pipeline of cleaning operations could have been performed more concisely with a list comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordclean = sorted(list(set([word.strip().lower() for word in wordlist])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'aa',\n",
       " 'aal',\n",
       " 'aalii',\n",
       " 'aam',\n",
       " 'aani',\n",
       " 'aardvark',\n",
       " 'aardwolf',\n",
       " 'aaron',\n",
       " 'aaronic']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordclean[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anagrams are words that can be created by using the same set of letters. A clever way to find anagrams is to use the 'sorted' function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e', 'i', 'l', 's', 'v']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted('elvis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted('lives') == sorted('elvis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an anagram 'signature'\n",
    "\n",
    "Let's write a function that creates a particular word's 'signature,' which in this context will mean the word sorted by letter in alphabetical order. Two words are anagrams if they have the same signature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signature(word):\n",
    "    return ''.join(sorted(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eilsv'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signature('elvis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anagram(myword):\n",
    "    return [word for word in wordclean if signature(word) == signature(myword)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dictionary', 'indicatory']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anagram('dictionary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function actually works fine, but calling it on a single word actually took a considerable amount of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293 ms ± 969 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 anagram('dictionary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "278 ms per loop is not good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_bysig = collections.defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list, {})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_bysig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in wordclean:\n",
    "    words_bysig[signature(word)].append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', ['a'])\n",
      "('aa', ['aa'])\n",
      "('aal', ['aal', 'ala'])\n",
      "('aaiil', ['aalii'])\n",
      "('aam', ['aam', 'ama'])\n",
      "('aain', ['aani'])\n",
      "('aaadkrrv', ['aardvark'])\n",
      "('aadflorw', ['aardwolf'])\n",
      "('aanor', ['aaron'])\n",
      "('aacinor', ['aaronic', 'nicarao', 'ocarina'])\n",
      "('aaacilnor', ['aaronical'])\n",
      "('aaeinort', ['aaronite', 'aeration'])\n",
      "('aaciinort', ['aaronitic'])\n",
      "('aaru', ['aaru', 'aura'])\n",
      "('ab', ['ab', 'ba'])\n",
      "('aab', ['aba', 'baa'])\n",
      "('aabbdeh', ['ababdeh'])\n",
      "('aaabbu', ['ababua'])\n",
      "('aabc', ['abac', 'caba'])\n",
      "('aaabc', ['abaca'])\n",
      "('aaabcet', ['abacate'])\n",
      "('aaabcy', ['abacay'])\n",
      "('aaabceint', ['abacinate'])\n",
      "('aaabciinnot', ['abacination'])\n",
      "('aabccissu', ['abaciscus'])\n",
      "('aabcist', ['abacist'])\n",
      "('aabck', ['aback'])\n",
      "('aaabcilnt', ['abactinal'])\n",
      "('aaabcillnty', ['abactinally'])\n",
      "('aabcinot', ['abaction'])\n",
      "('aabcort', ['abactor', 'acrobat'])\n",
      "('aabclsuu', ['abaculus'])\n",
      "('aabcsu', ['abacus'])\n",
      "('aabdeit', ['abadite'])\n",
      "('aabff', ['abaff'])\n",
      "('aabft', ['abaft', 'bafta'])\n",
      "('aaabceins', ['abaisance'])\n",
      "('aabeirs', ['abaiser'])\n",
      "('aabdeiss', ['abaissed'])\n",
      "('aaabeeilnt', ['abalienate'])\n",
      "('aaabeiilnnot', ['abalienation'])\n",
      "('aabelno', ['abalone', 'balonea'])\n",
      "('aaabm', ['abama'])\n",
      "('aabeempr', ['abampere'])\n",
      "('aabdnno', ['abandon'])\n",
      "('aaabbdelnno', ['abandonable'])\n",
      "('aabddenno', ['abandoned'])\n",
      "('aabddelnnoy', ['abandonedly'])\n",
      "('aabdeenno', ['abandonee'])\n",
      "('aabdennor', ['abandoner', 'reabandon'])\n",
      "('aabdemnnnot', ['abandonment'])\n",
      "('aabcin', ['abanic', 'bianca'])\n",
      "('aabenst', ['abantes'])\n",
      "('aabinopstt', ['abaptiston'])\n",
      "('aaabbmor', ['abarambo'])\n",
      "('aabirs', ['abaris', 'arabis'])\n",
      "('aabhiorrsst', ['abarthrosis'])\n",
      "('aaabcilrrtu', ['abarticular'])\n",
      "('aaabciilnorttu', ['abarticulation'])\n",
      "('aabs', ['abas', 'saba'])\n",
      "('aabes', ['abase'])\n",
      "('aabdes', ['abased'])\n",
      "('aabdelsy', ['abasedly'])\n",
      "('aabdeensss', ['abasedness'])\n",
      "('aabeemnst', ['abasement'])\n",
      "('aabers', ['abaser', 'abrase'])\n",
      "('aabgis', ['abasgi'])\n",
      "('aabhs', ['abash'])\n",
      "('aabdehs', ['abashed'])\n",
      "('aabdehlsy', ['abashedly'])\n",
      "('aabdeehnsss', ['abashedness'])\n",
      "('aabehlsss', ['abashless'])\n",
      "('aabehllsssy', ['abashlessly'])\n",
      "('aabehmnst', ['abashment'])\n",
      "('aaabis', ['abasia'])\n",
      "('aabcis', ['abasic'])\n",
      "('aabks', ['abask'])\n",
      "('aabinss', ['abassin'])\n",
      "('aaabdeirstz', ['abastardize'])\n",
      "('aaabbelt', ['abatable'])\n",
      "('aabet', ['abate', 'ateba', 'batea', 'beata'])\n",
      "('aabeemntt', ['abatement'])\n",
      "('aabert', ['abater', 'artabe', 'eartab', 'trabea'])\n",
      "('aabist', ['abatis'])\n",
      "('aabdeist', ['abatised'])\n",
      "('aabnot', ['abaton'])\n",
      "('aabort', ['abator'])\n",
      "('aabiortt', ['abattoir'])\n",
      "('aaabtu', ['abatua'])\n",
      "('aabertu', ['abature'])\n",
      "('aabev', ['abave'])\n",
      "('aaabilx', ['abaxial'])\n",
      "('aabeilx', ['abaxile'])\n",
      "('aabez', ['abaze'])\n",
      "('abb', ['abb', 'bab'])\n",
      "('aabb', ['abba', 'baba'])\n",
      "('aabbcemos', ['abbacomes'])\n",
      "('aabbcy', ['abbacy'])\n",
      "('aabbddei', ['abbadide'])\n",
      "('aabbs', ['abbas'])\n"
     ]
    }
   ],
   "source": [
    "for x in list(words_bysig.items())[:100]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in wordclean:\n",
    "    if signature(word) in test_dict:\n",
    "        test_dict[signature(word)].append(word)\n",
    "    else:\n",
    "        test_dict[signature(word)] = [word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', ['a'])\n",
      "('aa', ['aa'])\n",
      "('aal', ['aal', 'ala'])\n",
      "('aaiil', ['aalii'])\n",
      "('aam', ['aam', 'ama'])\n",
      "('aain', ['aani'])\n",
      "('aaadkrrv', ['aardvark'])\n",
      "('aadflorw', ['aardwolf'])\n",
      "('aanor', ['aaron'])\n",
      "('aacinor', ['aaronic', 'nicarao', 'ocarina'])\n",
      "('aaacilnor', ['aaronical'])\n",
      "('aaeinort', ['aaronite', 'aeration'])\n",
      "('aaciinort', ['aaronitic'])\n",
      "('aaru', ['aaru', 'aura'])\n",
      "('ab', ['ab', 'ba'])\n",
      "('aab', ['aba', 'baa'])\n",
      "('aabbdeh', ['ababdeh'])\n",
      "('aaabbu', ['ababua'])\n",
      "('aabc', ['abac', 'caba'])\n",
      "('aaabc', ['abaca'])\n",
      "('aaabcet', ['abacate'])\n",
      "('aaabcy', ['abacay'])\n",
      "('aaabceint', ['abacinate'])\n",
      "('aaabciinnot', ['abacination'])\n",
      "('aabccissu', ['abaciscus'])\n",
      "('aabcist', ['abacist'])\n",
      "('aabck', ['aback'])\n",
      "('aaabcilnt', ['abactinal'])\n",
      "('aaabcillnty', ['abactinally'])\n",
      "('aabcinot', ['abaction'])\n",
      "('aabcort', ['abactor', 'acrobat'])\n",
      "('aabclsuu', ['abaculus'])\n",
      "('aabcsu', ['abacus'])\n",
      "('aabdeit', ['abadite'])\n",
      "('aabff', ['abaff'])\n",
      "('aabft', ['abaft', 'bafta'])\n",
      "('aaabceins', ['abaisance'])\n",
      "('aabeirs', ['abaiser'])\n",
      "('aabdeiss', ['abaissed'])\n",
      "('aaabeeilnt', ['abalienate'])\n",
      "('aaabeiilnnot', ['abalienation'])\n",
      "('aabelno', ['abalone', 'balonea'])\n",
      "('aaabm', ['abama'])\n",
      "('aabeempr', ['abampere'])\n",
      "('aabdnno', ['abandon'])\n",
      "('aaabbdelnno', ['abandonable'])\n",
      "('aabddenno', ['abandoned'])\n",
      "('aabddelnnoy', ['abandonedly'])\n",
      "('aabdeenno', ['abandonee'])\n",
      "('aabdennor', ['abandoner', 'reabandon'])\n",
      "('aabdemnnnot', ['abandonment'])\n",
      "('aabcin', ['abanic', 'bianca'])\n",
      "('aabenst', ['abantes'])\n",
      "('aabinopstt', ['abaptiston'])\n",
      "('aaabbmor', ['abarambo'])\n",
      "('aabirs', ['abaris', 'arabis'])\n",
      "('aabhiorrsst', ['abarthrosis'])\n",
      "('aaabcilrrtu', ['abarticular'])\n",
      "('aaabciilnorttu', ['abarticulation'])\n",
      "('aabs', ['abas', 'saba'])\n",
      "('aabes', ['abase'])\n",
      "('aabdes', ['abased'])\n",
      "('aabdelsy', ['abasedly'])\n",
      "('aabdeensss', ['abasedness'])\n",
      "('aabeemnst', ['abasement'])\n",
      "('aabers', ['abaser', 'abrase'])\n",
      "('aabgis', ['abasgi'])\n",
      "('aabhs', ['abash'])\n",
      "('aabdehs', ['abashed'])\n",
      "('aabdehlsy', ['abashedly'])\n",
      "('aabdeehnsss', ['abashedness'])\n",
      "('aabehlsss', ['abashless'])\n",
      "('aabehllsssy', ['abashlessly'])\n",
      "('aabehmnst', ['abashment'])\n",
      "('aaabis', ['abasia'])\n",
      "('aabcis', ['abasic'])\n",
      "('aabks', ['abask'])\n",
      "('aabinss', ['abassin'])\n",
      "('aaabdeirstz', ['abastardize'])\n",
      "('aaabbelt', ['abatable'])\n",
      "('aabet', ['abate', 'ateba', 'batea', 'beata'])\n",
      "('aabeemntt', ['abatement'])\n",
      "('aabert', ['abater', 'artabe', 'eartab', 'trabea'])\n",
      "('aabist', ['abatis'])\n",
      "('aabdeist', ['abatised'])\n",
      "('aabnot', ['abaton'])\n",
      "('aabort', ['abator'])\n",
      "('aabiortt', ['abattoir'])\n",
      "('aaabtu', ['abatua'])\n",
      "('aabertu', ['abature'])\n",
      "('aabev', ['abave'])\n",
      "('aaabilx', ['abaxial'])\n",
      "('aabeilx', ['abaxile'])\n",
      "('aabez', ['abaze'])\n",
      "('abb', ['abb', 'bab'])\n",
      "('aabb', ['abba', 'baba'])\n",
      "('aabbcemos', ['abbacomes'])\n",
      "('aabbcy', ['abbacy'])\n",
      "('aabbddei', ['abbadide'])\n",
      "('aabbs', ['abbas'])\n"
     ]
    }
   ],
   "source": [
    "for x in list(test_dict.items())[:100]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_bysig == test_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have recreated the words_bysig dictionary without using the defaultdict from _collections_. The loop checks whether or not singature(word) is already a key in the dictionary. If it is, it appends the word to the item, which I instantiate as a list. Otherwise, it creates the key and assigns the word as the first item. The _defaultdict_ method creates a new key if one does not exist automatically, which is convenient.\n",
    "\n",
    "We will now find anagrams by simple dictionary lookup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anagram_fast(word):\n",
    "    return words_bysig[signature(word)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above function simply goes to the words_bysig signature key and returns the list stored as the key's values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dictionary', 'indicatory']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anagram_fast('dictionary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now collect all of the anagrams in wordclean, excluding the trivial anagrams, where the word is only an anagram of itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249 ms ± 3.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit anagrams_all = {word: anagram_fast(word) for word in wordclean if len(anagram_fast(word)) > 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "anagrams_all = {word: anagram_fast(word) for word in wordclean if len(anagram_fast(word)) > 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('aal', ['aal', 'ala']),\n",
       " ('aam', ['aam', 'ama']),\n",
       " ('aaronic', ['aaronic', 'nicarao', 'ocarina']),\n",
       " ('aaronite', ['aaronite', 'aeration']),\n",
       " ('aaru', ['aaru', 'aura']),\n",
       " ('ab', ['ab', 'ba']),\n",
       " ('aba', ['aba', 'baa']),\n",
       " ('abac', ['abac', 'caba']),\n",
       " ('abactor', ['abactor', 'acrobat']),\n",
       " ('abaft', ['abaft', 'bafta'])]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(anagrams_all.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32890"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(anagrams_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge:\n",
    "\n",
    "1. Separate words into classes based on length\n",
    "2. For each class of words, find the anagrams\n",
    "3. Count the total anagrams per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [len(word) for word in wordclean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lengths) == len(wordclean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234371"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_lengths = set(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pfds",
   "language": "python",
   "name": "pfds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
