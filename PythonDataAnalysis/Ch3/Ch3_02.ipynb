{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Studying Anagrams in the English Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = '/Users/mattjwilliams/Documents/LinkedInDataScience/PythonDataAnalysis/Exercise Files/Ch3/03_02/words'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(address, 'r') as f:\n",
    "    wordlist = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A\\n',\n",
       " 'a\\n',\n",
       " 'aa\\n',\n",
       " 'aal\\n',\n",
       " 'aalii\\n',\n",
       " 'aam\\n',\n",
       " 'Aani\\n',\n",
       " 'aardvark\\n',\n",
       " 'aardwolf\\n',\n",
       " 'Aaron\\n']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlist[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The worlist is read in, but it is desireable to remove the newline character at the end of each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235886"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordclean = [word.strip().lower() for word in wordlist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'a',\n",
       " 'aa',\n",
       " 'aal',\n",
       " 'aalii',\n",
       " 'aam',\n",
       " 'aani',\n",
       " 'aardvark',\n",
       " 'aardwolf',\n",
       " 'aaron']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordclean[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordunique = list(set(wordclean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bocca',\n",
       " 'cheapness',\n",
       " 'spurn',\n",
       " 'bakeshop',\n",
       " 'multinuclear',\n",
       " 'pouting',\n",
       " 'forcefully',\n",
       " 'counterpaly',\n",
       " 'sensationish',\n",
       " 'blaver']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordunique[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I converted to a set, which contains only unique instances of a list, in order to get rid of the duplicates. But doing so lost the alphabetical order of the original list, so we will need to sort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordunique.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'aa',\n",
       " 'aal',\n",
       " 'aalii',\n",
       " 'aam',\n",
       " 'aani',\n",
       " 'aardvark',\n",
       " 'aardwolf',\n",
       " 'aaron',\n",
       " 'aaronic']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordunique[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This pipeline of cleaning operations could have been performed more concisely with a list comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordclean = sorted(list(set([word.strip().lower() for word in wordlist])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'aa',\n",
       " 'aal',\n",
       " 'aalii',\n",
       " 'aam',\n",
       " 'aani',\n",
       " 'aardvark',\n",
       " 'aardwolf',\n",
       " 'aaron',\n",
       " 'aaronic']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordclean[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anagrams are words that can be created by using the same set of letters. A clever way to find anagrams is to use the 'sorted' function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e', 'i', 'l', 's', 'v']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted('elvis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted('lives') == sorted('elvis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an anagram 'signature'\n",
    "\n",
    "Let's write a function that creates a particular word's 'signature,' which in this context will mean the word sorted by letter in alphabetical order. Two words are anagrams if they have the same signature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signature(word):\n",
    "    return ''.join(sorted(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eilsv'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signature('elvis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anagram(myword):\n",
    "    return [word for word in wordclean if signature(word) == signature(myword)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dictionary', 'indicatory']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anagram('dictionary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function actually works fine, but calling it on a single word actually took a considerable amount of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293 ms ± 969 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 anagram('dictionary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "278 ms per loop is not good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_bysig = collections.defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list, {})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_bysig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in wordclean:\n",
    "    words_bysig[signature(word)].append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', ['a'])\n",
      "('aa', ['aa'])\n",
      "('aal', ['aal', 'ala'])\n",
      "('aaiil', ['aalii'])\n",
      "('aam', ['aam', 'ama'])\n",
      "('aain', ['aani'])\n",
      "('aaadkrrv', ['aardvark'])\n",
      "('aadflorw', ['aardwolf'])\n",
      "('aanor', ['aaron'])\n",
      "('aacinor', ['aaronic', 'nicarao', 'ocarina'])\n",
      "('aaacilnor', ['aaronical'])\n",
      "('aaeinort', ['aaronite', 'aeration'])\n",
      "('aaciinort', ['aaronitic'])\n",
      "('aaru', ['aaru', 'aura'])\n",
      "('ab', ['ab', 'ba'])\n",
      "('aab', ['aba', 'baa'])\n",
      "('aabbdeh', ['ababdeh'])\n",
      "('aaabbu', ['ababua'])\n",
      "('aabc', ['abac', 'caba'])\n",
      "('aaabc', ['abaca'])\n",
      "('aaabcet', ['abacate'])\n",
      "('aaabcy', ['abacay'])\n",
      "('aaabceint', ['abacinate'])\n",
      "('aaabciinnot', ['abacination'])\n",
      "('aabccissu', ['abaciscus'])\n",
      "('aabcist', ['abacist'])\n",
      "('aabck', ['aback'])\n",
      "('aaabcilnt', ['abactinal'])\n",
      "('aaabcillnty', ['abactinally'])\n",
      "('aabcinot', ['abaction'])\n",
      "('aabcort', ['abactor', 'acrobat'])\n",
      "('aabclsuu', ['abaculus'])\n",
      "('aabcsu', ['abacus'])\n",
      "('aabdeit', ['abadite'])\n",
      "('aabff', ['abaff'])\n",
      "('aabft', ['abaft', 'bafta'])\n",
      "('aaabceins', ['abaisance'])\n",
      "('aabeirs', ['abaiser'])\n",
      "('aabdeiss', ['abaissed'])\n",
      "('aaabeeilnt', ['abalienate'])\n",
      "('aaabeiilnnot', ['abalienation'])\n",
      "('aabelno', ['abalone', 'balonea'])\n",
      "('aaabm', ['abama'])\n",
      "('aabeempr', ['abampere'])\n",
      "('aabdnno', ['abandon'])\n",
      "('aaabbdelnno', ['abandonable'])\n",
      "('aabddenno', ['abandoned'])\n",
      "('aabddelnnoy', ['abandonedly'])\n",
      "('aabdeenno', ['abandonee'])\n",
      "('aabdennor', ['abandoner', 'reabandon'])\n",
      "('aabdemnnnot', ['abandonment'])\n",
      "('aabcin', ['abanic', 'bianca'])\n",
      "('aabenst', ['abantes'])\n",
      "('aabinopstt', ['abaptiston'])\n",
      "('aaabbmor', ['abarambo'])\n",
      "('aabirs', ['abaris', 'arabis'])\n",
      "('aabhiorrsst', ['abarthrosis'])\n",
      "('aaabcilrrtu', ['abarticular'])\n",
      "('aaabciilnorttu', ['abarticulation'])\n",
      "('aabs', ['abas', 'saba'])\n",
      "('aabes', ['abase'])\n",
      "('aabdes', ['abased'])\n",
      "('aabdelsy', ['abasedly'])\n",
      "('aabdeensss', ['abasedness'])\n",
      "('aabeemnst', ['abasement'])\n",
      "('aabers', ['abaser', 'abrase'])\n",
      "('aabgis', ['abasgi'])\n",
      "('aabhs', ['abash'])\n",
      "('aabdehs', ['abashed'])\n",
      "('aabdehlsy', ['abashedly'])\n",
      "('aabdeehnsss', ['abashedness'])\n",
      "('aabehlsss', ['abashless'])\n",
      "('aabehllsssy', ['abashlessly'])\n",
      "('aabehmnst', ['abashment'])\n",
      "('aaabis', ['abasia'])\n",
      "('aabcis', ['abasic'])\n",
      "('aabks', ['abask'])\n",
      "('aabinss', ['abassin'])\n",
      "('aaabdeirstz', ['abastardize'])\n",
      "('aaabbelt', ['abatable'])\n",
      "('aabet', ['abate', 'ateba', 'batea', 'beata'])\n",
      "('aabeemntt', ['abatement'])\n",
      "('aabert', ['abater', 'artabe', 'eartab', 'trabea'])\n",
      "('aabist', ['abatis'])\n",
      "('aabdeist', ['abatised'])\n",
      "('aabnot', ['abaton'])\n",
      "('aabort', ['abator'])\n",
      "('aabiortt', ['abattoir'])\n",
      "('aaabtu', ['abatua'])\n",
      "('aabertu', ['abature'])\n",
      "('aabev', ['abave'])\n",
      "('aaabilx', ['abaxial'])\n",
      "('aabeilx', ['abaxile'])\n",
      "('aabez', ['abaze'])\n",
      "('abb', ['abb', 'bab'])\n",
      "('aabb', ['abba', 'baba'])\n",
      "('aabbcemos', ['abbacomes'])\n",
      "('aabbcy', ['abbacy'])\n",
      "('aabbddei', ['abbadide'])\n",
      "('aabbs', ['abbas'])\n"
     ]
    }
   ],
   "source": [
    "for x in list(words_bysig.items())[:100]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in wordclean:\n",
    "    if signature(word) in test_dict:\n",
    "        test_dict[signature(word)].append(word)\n",
    "    else:\n",
    "        test_dict[signature(word)] = [word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', ['a'])\n",
      "('aa', ['aa'])\n",
      "('aal', ['aal', 'ala'])\n",
      "('aaiil', ['aalii'])\n",
      "('aam', ['aam', 'ama'])\n",
      "('aain', ['aani'])\n",
      "('aaadkrrv', ['aardvark'])\n",
      "('aadflorw', ['aardwolf'])\n",
      "('aanor', ['aaron'])\n",
      "('aacinor', ['aaronic', 'nicarao', 'ocarina'])\n",
      "('aaacilnor', ['aaronical'])\n",
      "('aaeinort', ['aaronite', 'aeration'])\n",
      "('aaciinort', ['aaronitic'])\n",
      "('aaru', ['aaru', 'aura'])\n",
      "('ab', ['ab', 'ba'])\n",
      "('aab', ['aba', 'baa'])\n",
      "('aabbdeh', ['ababdeh'])\n",
      "('aaabbu', ['ababua'])\n",
      "('aabc', ['abac', 'caba'])\n",
      "('aaabc', ['abaca'])\n",
      "('aaabcet', ['abacate'])\n",
      "('aaabcy', ['abacay'])\n",
      "('aaabceint', ['abacinate'])\n",
      "('aaabciinnot', ['abacination'])\n",
      "('aabccissu', ['abaciscus'])\n",
      "('aabcist', ['abacist'])\n",
      "('aabck', ['aback'])\n",
      "('aaabcilnt', ['abactinal'])\n",
      "('aaabcillnty', ['abactinally'])\n",
      "('aabcinot', ['abaction'])\n",
      "('aabcort', ['abactor', 'acrobat'])\n",
      "('aabclsuu', ['abaculus'])\n",
      "('aabcsu', ['abacus'])\n",
      "('aabdeit', ['abadite'])\n",
      "('aabff', ['abaff'])\n",
      "('aabft', ['abaft', 'bafta'])\n",
      "('aaabceins', ['abaisance'])\n",
      "('aabeirs', ['abaiser'])\n",
      "('aabdeiss', ['abaissed'])\n",
      "('aaabeeilnt', ['abalienate'])\n",
      "('aaabeiilnnot', ['abalienation'])\n",
      "('aabelno', ['abalone', 'balonea'])\n",
      "('aaabm', ['abama'])\n",
      "('aabeempr', ['abampere'])\n",
      "('aabdnno', ['abandon'])\n",
      "('aaabbdelnno', ['abandonable'])\n",
      "('aabddenno', ['abandoned'])\n",
      "('aabddelnnoy', ['abandonedly'])\n",
      "('aabdeenno', ['abandonee'])\n",
      "('aabdennor', ['abandoner', 'reabandon'])\n",
      "('aabdemnnnot', ['abandonment'])\n",
      "('aabcin', ['abanic', 'bianca'])\n",
      "('aabenst', ['abantes'])\n",
      "('aabinopstt', ['abaptiston'])\n",
      "('aaabbmor', ['abarambo'])\n",
      "('aabirs', ['abaris', 'arabis'])\n",
      "('aabhiorrsst', ['abarthrosis'])\n",
      "('aaabcilrrtu', ['abarticular'])\n",
      "('aaabciilnorttu', ['abarticulation'])\n",
      "('aabs', ['abas', 'saba'])\n",
      "('aabes', ['abase'])\n",
      "('aabdes', ['abased'])\n",
      "('aabdelsy', ['abasedly'])\n",
      "('aabdeensss', ['abasedness'])\n",
      "('aabeemnst', ['abasement'])\n",
      "('aabers', ['abaser', 'abrase'])\n",
      "('aabgis', ['abasgi'])\n",
      "('aabhs', ['abash'])\n",
      "('aabdehs', ['abashed'])\n",
      "('aabdehlsy', ['abashedly'])\n",
      "('aabdeehnsss', ['abashedness'])\n",
      "('aabehlsss', ['abashless'])\n",
      "('aabehllsssy', ['abashlessly'])\n",
      "('aabehmnst', ['abashment'])\n",
      "('aaabis', ['abasia'])\n",
      "('aabcis', ['abasic'])\n",
      "('aabks', ['abask'])\n",
      "('aabinss', ['abassin'])\n",
      "('aaabdeirstz', ['abastardize'])\n",
      "('aaabbelt', ['abatable'])\n",
      "('aabet', ['abate', 'ateba', 'batea', 'beata'])\n",
      "('aabeemntt', ['abatement'])\n",
      "('aabert', ['abater', 'artabe', 'eartab', 'trabea'])\n",
      "('aabist', ['abatis'])\n",
      "('aabdeist', ['abatised'])\n",
      "('aabnot', ['abaton'])\n",
      "('aabort', ['abator'])\n",
      "('aabiortt', ['abattoir'])\n",
      "('aaabtu', ['abatua'])\n",
      "('aabertu', ['abature'])\n",
      "('aabev', ['abave'])\n",
      "('aaabilx', ['abaxial'])\n",
      "('aabeilx', ['abaxile'])\n",
      "('aabez', ['abaze'])\n",
      "('abb', ['abb', 'bab'])\n",
      "('aabb', ['abba', 'baba'])\n",
      "('aabbcemos', ['abbacomes'])\n",
      "('aabbcy', ['abbacy'])\n",
      "('aabbddei', ['abbadide'])\n",
      "('aabbs', ['abbas'])\n"
     ]
    }
   ],
   "source": [
    "for x in list(test_dict.items())[:100]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_bysig == test_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have recreated the words_bysig dictionary without using the defaultdict from _collections_. The loop checks whether or not singature(word) is already a key in the dictionary. If it is, it appends the word to the item, which I instantiate as a list. Otherwise, it creates the key and assigns the word as the first item. The _defaultdict_ method creates a new key if one does not exist automatically, which is convenient.\n",
    "\n",
    "We will now find anagrams by simple dictionary lookup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anagram_fast(word):\n",
    "    return words_bysig[signature(word)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above function simply goes to the words_bysig signature key and returns the list stored as the key's values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dictionary', 'indicatory']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anagram_fast('dictionary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now collect all of the anagrams in wordclean, excluding the trivial anagrams, where the word is only an anagram of itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249 ms ± 3.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit anagrams_all = {word: anagram_fast(word) for word in wordclean if len(anagram_fast(word)) > 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "anagrams_all = {word: anagram_fast(word) for word in wordclean if len(anagram_fast(word)) > 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('aal', ['aal', 'ala']),\n",
       " ('aam', ['aam', 'ama']),\n",
       " ('aaronic', ['aaronic', 'nicarao', 'ocarina']),\n",
       " ('aaronite', ['aaronite', 'aeration']),\n",
       " ('aaru', ['aaru', 'aura']),\n",
       " ('ab', ['ab', 'ba']),\n",
       " ('aba', ['aba', 'baa']),\n",
       " ('abac', ['abac', 'caba']),\n",
       " ('abactor', ['abactor', 'acrobat']),\n",
       " ('abaft', ['abaft', 'bafta'])]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(anagrams_all.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32890"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(anagrams_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge:\n",
    "\n",
    "1. Separate words into classes based on length\n",
    "2. For each class of words, find the anagrams\n",
    "3. Count the total anagrams per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [len(word) for word in wordclean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lengths) == len(wordclean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234371"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_lengths = set(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_dict = {}\n",
    "for word in wordclean:\n",
    "    if len(word) in len_dict:\n",
    "        len_dict[len(word)].append(word)\n",
    "    else:\n",
    "        len_dict[len(word)] = [word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  ['a',\n",
       "   'b',\n",
       "   'c',\n",
       "   'd',\n",
       "   'e',\n",
       "   'f',\n",
       "   'g',\n",
       "   'h',\n",
       "   'i',\n",
       "   'j',\n",
       "   'k',\n",
       "   'l',\n",
       "   'm',\n",
       "   'n',\n",
       "   'o',\n",
       "   'p',\n",
       "   'q',\n",
       "   'r',\n",
       "   's',\n",
       "   't',\n",
       "   'u',\n",
       "   'v',\n",
       "   'w',\n",
       "   'x',\n",
       "   'y',\n",
       "   'z']),\n",
       " (2,\n",
       "  ['aa',\n",
       "   'ab',\n",
       "   'ad',\n",
       "   'ae',\n",
       "   'ah',\n",
       "   'ai',\n",
       "   'ak',\n",
       "   'al',\n",
       "   'am',\n",
       "   'an',\n",
       "   'ao',\n",
       "   'ar',\n",
       "   'as',\n",
       "   'at',\n",
       "   'aw',\n",
       "   'ax',\n",
       "   'ay',\n",
       "   'ba',\n",
       "   'be',\n",
       "   'bo',\n",
       "   'bu',\n",
       "   'by',\n",
       "   'ca',\n",
       "   'ce',\n",
       "   'da',\n",
       "   'de',\n",
       "   'di',\n",
       "   'do',\n",
       "   'ea',\n",
       "   'ed',\n",
       "   'eh',\n",
       "   'el',\n",
       "   'em',\n",
       "   'en',\n",
       "   'er',\n",
       "   'es',\n",
       "   'eu',\n",
       "   'ex',\n",
       "   'ey',\n",
       "   'fa',\n",
       "   'fe',\n",
       "   'fi',\n",
       "   'fo',\n",
       "   'fu',\n",
       "   'ga',\n",
       "   'ge',\n",
       "   'gi',\n",
       "   'go',\n",
       "   'ha',\n",
       "   'he',\n",
       "   'hi',\n",
       "   'ho',\n",
       "   'hu',\n",
       "   'hy',\n",
       "   'id',\n",
       "   'ie',\n",
       "   'if',\n",
       "   'in',\n",
       "   'io',\n",
       "   'is',\n",
       "   'it',\n",
       "   'ji',\n",
       "   'jo',\n",
       "   'ju',\n",
       "   'ka',\n",
       "   'ko',\n",
       "   'la',\n",
       "   'li',\n",
       "   'lo',\n",
       "   'lu',\n",
       "   'ly',\n",
       "   'ma',\n",
       "   'me',\n",
       "   'mi',\n",
       "   'mo',\n",
       "   'mr',\n",
       "   'mu',\n",
       "   'my',\n",
       "   'na',\n",
       "   'ne',\n",
       "   'ni',\n",
       "   'no',\n",
       "   'nu',\n",
       "   'od',\n",
       "   'oe',\n",
       "   'of',\n",
       "   'og',\n",
       "   'oh',\n",
       "   'ok',\n",
       "   'om',\n",
       "   'on',\n",
       "   'or',\n",
       "   'os',\n",
       "   'ow',\n",
       "   'ox',\n",
       "   'pa',\n",
       "   'pi',\n",
       "   'po',\n",
       "   'pu',\n",
       "   'ra',\n",
       "   're',\n",
       "   'ro',\n",
       "   'sa',\n",
       "   'se',\n",
       "   'sh',\n",
       "   'si',\n",
       "   'so',\n",
       "   'st',\n",
       "   'ta',\n",
       "   'td',\n",
       "   'te',\n",
       "   'th',\n",
       "   'ti',\n",
       "   'to',\n",
       "   'tu',\n",
       "   'ud',\n",
       "   'ug',\n",
       "   'um',\n",
       "   'un',\n",
       "   'up',\n",
       "   'ur',\n",
       "   'us',\n",
       "   'ut',\n",
       "   'vu',\n",
       "   'wa',\n",
       "   'we',\n",
       "   'wi',\n",
       "   'wo',\n",
       "   'wu',\n",
       "   'wy',\n",
       "   'xi',\n",
       "   'ya',\n",
       "   'ye',\n",
       "   'ym',\n",
       "   'yn',\n",
       "   'yo',\n",
       "   'yr',\n",
       "   'za',\n",
       "   'zo']),\n",
       " (3,\n",
       "  ['aal',\n",
       "   'aam',\n",
       "   'aba',\n",
       "   'abb',\n",
       "   'abe',\n",
       "   'abo',\n",
       "   'abu',\n",
       "   'aby',\n",
       "   'ace',\n",
       "   'ach',\n",
       "   'act',\n",
       "   'ada',\n",
       "   'add',\n",
       "   'ade',\n",
       "   'ado',\n",
       "   'ady',\n",
       "   'adz',\n",
       "   'aer',\n",
       "   'aes',\n",
       "   'aft',\n",
       "   'aga',\n",
       "   'age',\n",
       "   'ago',\n",
       "   'agy',\n",
       "   'aha',\n",
       "   'aho',\n",
       "   'aht',\n",
       "   'ahu',\n",
       "   'aid',\n",
       "   'ail',\n",
       "   'aim',\n",
       "   'air',\n",
       "   'ait',\n",
       "   'aix',\n",
       "   'aka',\n",
       "   'ake',\n",
       "   'ako',\n",
       "   'aku',\n",
       "   'ala',\n",
       "   'alb',\n",
       "   'ale',\n",
       "   'alf',\n",
       "   'alk',\n",
       "   'all',\n",
       "   'aln',\n",
       "   'alo',\n",
       "   'alp',\n",
       "   'alt',\n",
       "   'aly',\n",
       "   'ama',\n",
       "   'ame',\n",
       "   'ami',\n",
       "   'amt',\n",
       "   'amy',\n",
       "   'ana',\n",
       "   'and',\n",
       "   'ani',\n",
       "   'ann',\n",
       "   'ant',\n",
       "   'any',\n",
       "   'apa',\n",
       "   'ape',\n",
       "   'apt',\n",
       "   'ara',\n",
       "   'arc',\n",
       "   'are',\n",
       "   'ark',\n",
       "   'arm',\n",
       "   'arn',\n",
       "   'aro',\n",
       "   'art',\n",
       "   'aru',\n",
       "   'arx',\n",
       "   'ary',\n",
       "   'asa',\n",
       "   'ase',\n",
       "   'ash',\n",
       "   'ask',\n",
       "   'asp',\n",
       "   'ass',\n",
       "   'ast',\n",
       "   'ata',\n",
       "   'ate',\n",
       "   'ati',\n",
       "   'auh',\n",
       "   'auk',\n",
       "   'aum',\n",
       "   'aus',\n",
       "   'ava',\n",
       "   'ave',\n",
       "   'avo',\n",
       "   'awa',\n",
       "   'awd',\n",
       "   'awe',\n",
       "   'awl',\n",
       "   'awn',\n",
       "   'axe',\n",
       "   'aye',\n",
       "   'ayu',\n",
       "   'azo',\n",
       "   'baa',\n",
       "   'bab',\n",
       "   'bac',\n",
       "   'bad',\n",
       "   'bae',\n",
       "   'bag',\n",
       "   'bah',\n",
       "   'bal',\n",
       "   'bam',\n",
       "   'ban',\n",
       "   'bap',\n",
       "   'bar',\n",
       "   'bas',\n",
       "   'bat',\n",
       "   'baw',\n",
       "   'bay',\n",
       "   'bea',\n",
       "   'bed',\n",
       "   'bee',\n",
       "   'beg',\n",
       "   'bel',\n",
       "   'ben',\n",
       "   'ber',\n",
       "   'bes',\n",
       "   'bet',\n",
       "   'bey',\n",
       "   'bib',\n",
       "   'bid',\n",
       "   'big',\n",
       "   'bim',\n",
       "   'bin',\n",
       "   'bis',\n",
       "   'bit',\n",
       "   'biz',\n",
       "   'blo',\n",
       "   'boa',\n",
       "   'bob',\n",
       "   'bod',\n",
       "   'bog',\n",
       "   'bom',\n",
       "   'bon',\n",
       "   'boo',\n",
       "   'bop',\n",
       "   'bor',\n",
       "   'bos',\n",
       "   'bot',\n",
       "   'bow',\n",
       "   'boy',\n",
       "   'bra',\n",
       "   'bub',\n",
       "   'bud',\n",
       "   'bug',\n",
       "   'bum',\n",
       "   'bun',\n",
       "   'bur',\n",
       "   'bus',\n",
       "   'but',\n",
       "   'buy',\n",
       "   'bye',\n",
       "   'cab',\n",
       "   'cad',\n",
       "   'cag',\n",
       "   'cal',\n",
       "   'cam',\n",
       "   'can',\n",
       "   'cap',\n",
       "   'car',\n",
       "   'cat',\n",
       "   'caw',\n",
       "   'cay',\n",
       "   'cee',\n",
       "   'cep',\n",
       "   'cha',\n",
       "   'che',\n",
       "   'chi',\n",
       "   'cho',\n",
       "   'cid',\n",
       "   'cig',\n",
       "   'cit',\n",
       "   'cly',\n",
       "   'cob',\n",
       "   'cod',\n",
       "   'coe',\n",
       "   'cog',\n",
       "   'col',\n",
       "   'con',\n",
       "   'coo',\n",
       "   'cop',\n",
       "   'cor',\n",
       "   'cos',\n",
       "   'cot',\n",
       "   'cow',\n",
       "   'cox',\n",
       "   'coy',\n",
       "   'coz',\n",
       "   'cro',\n",
       "   'cry',\n",
       "   'cub',\n",
       "   'cud',\n",
       "   'cue',\n",
       "   'cum',\n",
       "   'cup',\n",
       "   'cur',\n",
       "   'cut',\n",
       "   'cwm',\n",
       "   'cyp',\n",
       "   'dab',\n",
       "   'dad',\n",
       "   'dae',\n",
       "   'dag',\n",
       "   'dah',\n",
       "   'dak',\n",
       "   'dal',\n",
       "   'dam',\n",
       "   'dan',\n",
       "   'dao',\n",
       "   'dap',\n",
       "   'dar',\n",
       "   'das',\n",
       "   'daw',\n",
       "   'day',\n",
       "   'deb',\n",
       "   'dee',\n",
       "   'deg',\n",
       "   'del',\n",
       "   'den',\n",
       "   'dev',\n",
       "   'dew',\n",
       "   'dey',\n",
       "   'dha',\n",
       "   'dhu',\n",
       "   'dib',\n",
       "   'did',\n",
       "   'die',\n",
       "   'dig',\n",
       "   'dim',\n",
       "   'din',\n",
       "   'dip',\n",
       "   'dis',\n",
       "   'dit',\n",
       "   'div',\n",
       "   'dob',\n",
       "   'doc',\n",
       "   'dod',\n",
       "   'doe',\n",
       "   'dog',\n",
       "   'dol',\n",
       "   'dom',\n",
       "   'don',\n",
       "   'dop',\n",
       "   'dor',\n",
       "   'dos',\n",
       "   'dot',\n",
       "   'dow',\n",
       "   'dry',\n",
       "   'dub',\n",
       "   'dud',\n",
       "   'due',\n",
       "   'dug',\n",
       "   'dum',\n",
       "   'dun',\n",
       "   'duo',\n",
       "   'dup',\n",
       "   'dux',\n",
       "   'dye',\n",
       "   'ean',\n",
       "   'ear',\n",
       "   'eat',\n",
       "   'ebb',\n",
       "   'edh',\n",
       "   'edo',\n",
       "   'eel',\n",
       "   'eer',\n",
       "   'eft',\n",
       "   'egg',\n",
       "   'ego',\n",
       "   'eke',\n",
       "   'elb',\n",
       "   'eld',\n",
       "   'elf',\n",
       "   'eli',\n",
       "   'elk',\n",
       "   'ell',\n",
       "   'elm',\n",
       "   'els',\n",
       "   'elt',\n",
       "   'eme',\n",
       "   'emm',\n",
       "   'emu',\n",
       "   'end',\n",
       "   'ens',\n",
       "   'eon',\n",
       "   'era',\n",
       "   'erd',\n",
       "   'ere',\n",
       "   'erg',\n",
       "   'err',\n",
       "   'ers',\n",
       "   'ess',\n",
       "   'eta',\n",
       "   'eva',\n",
       "   'eve',\n",
       "   'ewe',\n",
       "   'eye',\n",
       "   'eyn',\n",
       "   'fad',\n",
       "   'fae',\n",
       "   'fag',\n",
       "   'fam',\n",
       "   'fan',\n",
       "   'far',\n",
       "   'fat',\n",
       "   'fay',\n",
       "   'fed',\n",
       "   'fee',\n",
       "   'fei',\n",
       "   'fen',\n",
       "   'fet',\n",
       "   'feu',\n",
       "   'few',\n",
       "   'fey',\n",
       "   'fez',\n",
       "   'fib',\n",
       "   'fid',\n",
       "   'fie',\n",
       "   'fig',\n",
       "   'fin',\n",
       "   'fip',\n",
       "   'fir',\n",
       "   'fit',\n",
       "   'fix',\n",
       "   'flo',\n",
       "   'flu',\n",
       "   'fly',\n",
       "   'fob',\n",
       "   'fod',\n",
       "   'foe',\n",
       "   'fog',\n",
       "   'fon',\n",
       "   'foo',\n",
       "   'fop',\n",
       "   'for',\n",
       "   'fot',\n",
       "   'fou',\n",
       "   'fow',\n",
       "   'fox',\n",
       "   'foy',\n",
       "   'fra',\n",
       "   'fro',\n",
       "   'fry',\n",
       "   'fub',\n",
       "   'fud',\n",
       "   'fum',\n",
       "   'fun',\n",
       "   'fur',\n",
       "   'fut',\n",
       "   'gab',\n",
       "   'gad',\n",
       "   'gag',\n",
       "   'gaj',\n",
       "   'gal',\n",
       "   'gam',\n",
       "   'gan',\n",
       "   'gap',\n",
       "   'gar',\n",
       "   'gas',\n",
       "   'gat',\n",
       "   'gau',\n",
       "   'gaw',\n",
       "   'gay',\n",
       "   'gaz',\n",
       "   'ged',\n",
       "   'gee',\n",
       "   'gel',\n",
       "   'gem',\n",
       "   'gen',\n",
       "   'geo',\n",
       "   'ger',\n",
       "   'ges',\n",
       "   'get',\n",
       "   'gey',\n",
       "   'gez',\n",
       "   'gib',\n",
       "   'gid',\n",
       "   'gie',\n",
       "   'gif',\n",
       "   'gig',\n",
       "   'gil',\n",
       "   'gim',\n",
       "   'gin',\n",
       "   'gio',\n",
       "   'gip',\n",
       "   'git',\n",
       "   'gnu',\n",
       "   'goa',\n",
       "   'gob',\n",
       "   'god',\n",
       "   'gog',\n",
       "   'goi',\n",
       "   'gol',\n",
       "   'gon',\n",
       "   'goo',\n",
       "   'gor',\n",
       "   'gos',\n",
       "   'got',\n",
       "   'goy',\n",
       "   'gra',\n",
       "   'grr',\n",
       "   'gud',\n",
       "   'gue',\n",
       "   'gul',\n",
       "   'gum',\n",
       "   'gun',\n",
       "   'gup',\n",
       "   'gur',\n",
       "   'gus',\n",
       "   'gut',\n",
       "   'guy',\n",
       "   'guz',\n",
       "   'gym',\n",
       "   'gyn',\n",
       "   'gyp',\n",
       "   'had',\n",
       "   'hag',\n",
       "   'hah',\n",
       "   'hak',\n",
       "   'hal',\n",
       "   'ham',\n",
       "   'han',\n",
       "   'hao',\n",
       "   'hap',\n",
       "   'hat',\n",
       "   'hau',\n",
       "   'haw',\n",
       "   'hay',\n",
       "   'hei',\n",
       "   'hem',\n",
       "   'hen',\n",
       "   'hep',\n",
       "   'her',\n",
       "   'het',\n",
       "   'hew',\n",
       "   'hex',\n",
       "   'hey',\n",
       "   'hia',\n",
       "   'hic',\n",
       "   'hie',\n",
       "   'him',\n",
       "   'hin',\n",
       "   'hip',\n",
       "   'his',\n",
       "   'hit',\n",
       "   'hob',\n",
       "   'hod',\n",
       "   'hoe',\n",
       "   'hog',\n",
       "   'hoi',\n",
       "   'hon',\n",
       "   'hop',\n",
       "   'hot',\n",
       "   'how',\n",
       "   'hox',\n",
       "   'hoy',\n",
       "   'hsi',\n",
       "   'hub',\n",
       "   'hud',\n",
       "   'hue',\n",
       "   'hug',\n",
       "   'huh',\n",
       "   'hui',\n",
       "   'huk',\n",
       "   'hum',\n",
       "   'hun',\n",
       "   'hup',\n",
       "   'hut',\n",
       "   'hwa',\n",
       "   'hyp',\n",
       "   'ian',\n",
       "   'iao',\n",
       "   'iba',\n",
       "   'ibo',\n",
       "   'ice',\n",
       "   'ich',\n",
       "   'icy',\n",
       "   'ida',\n",
       "   'ide',\n",
       "   'ido',\n",
       "   'ife',\n",
       "   'ihi',\n",
       "   'ijo',\n",
       "   'ike',\n",
       "   'ila',\n",
       "   'ilk',\n",
       "   'ill',\n",
       "   'ima',\n",
       "   'imi',\n",
       "   'imp',\n",
       "   'imu',\n",
       "   'ind',\n",
       "   'ing',\n",
       "   'ink',\n",
       "   'inn',\n",
       "   'ino',\n",
       "   'ion',\n",
       "   'ira',\n",
       "   'ire',\n",
       "   'irk',\n",
       "   'ism',\n",
       "   'iso',\n",
       "   'ist',\n",
       "   'ita',\n",
       "   'ito',\n",
       "   'its',\n",
       "   'iva',\n",
       "   'ivy',\n",
       "   'iwa',\n",
       "   'iyo',\n",
       "   'jab',\n",
       "   'jag',\n",
       "   'jam',\n",
       "   'jan',\n",
       "   'jap',\n",
       "   'jar',\n",
       "   'jat',\n",
       "   'jaw',\n",
       "   'jay',\n",
       "   'jed',\n",
       "   'jef',\n",
       "   'jem',\n",
       "   'jet',\n",
       "   'jew',\n",
       "   'jib',\n",
       "   'jig',\n",
       "   'jim',\n",
       "   'jin',\n",
       "   'job',\n",
       "   'joe',\n",
       "   'jog',\n",
       "   'jon',\n",
       "   'jos',\n",
       "   'jot',\n",
       "   'jow',\n",
       "   'joy',\n",
       "   'jud',\n",
       "   'jug',\n",
       "   'jun',\n",
       "   'jur',\n",
       "   'jut',\n",
       "   'kaf',\n",
       "   'kai',\n",
       "   'kaj',\n",
       "   'kan',\n",
       "   'kat',\n",
       "   'kaw',\n",
       "   'kay',\n",
       "   'kea',\n",
       "   'keb',\n",
       "   'ked',\n",
       "   'kee',\n",
       "   'kef',\n",
       "   'keg',\n",
       "   'ken',\n",
       "   'kep',\n",
       "   'ker',\n",
       "   'ket',\n",
       "   'kex',\n",
       "   'key',\n",
       "   'kha',\n",
       "   'khu',\n",
       "   'kil',\n",
       "   'kim',\n",
       "   'kin',\n",
       "   'kip',\n",
       "   'kit',\n",
       "   'koa',\n",
       "   'kob',\n",
       "   'koi',\n",
       "   'kol',\n",
       "   'kon',\n",
       "   'kop',\n",
       "   'kor',\n",
       "   'kos',\n",
       "   'kou',\n",
       "   'kra',\n",
       "   'kru',\n",
       "   'kua',\n",
       "   'kui',\n",
       "   'kyl',\n",
       "   'kyu',\n",
       "   'lab',\n",
       "   'lac',\n",
       "   'lad',\n",
       "   'lag',\n",
       "   'lai',\n",
       "   'lak',\n",
       "   'lam',\n",
       "   'lan',\n",
       "   'lao',\n",
       "   'lap',\n",
       "   'lar',\n",
       "   'las',\n",
       "   'lat',\n",
       "   'law',\n",
       "   'lax',\n",
       "   'lay',\n",
       "   'laz',\n",
       "   'lea',\n",
       "   'led',\n",
       "   'lee',\n",
       "   'leg',\n",
       "   'lei',\n",
       "   'lek',\n",
       "   'len',\n",
       "   'leo',\n",
       "   'ler',\n",
       "   'les',\n",
       "   'let',\n",
       "   'leu',\n",
       "   'lev',\n",
       "   'lew',\n",
       "   'lex',\n",
       "   'ley',\n",
       "   'lid',\n",
       "   'lie',\n",
       "   'lif',\n",
       "   'lim',\n",
       "   'lin',\n",
       "   'lip',\n",
       "   'lis',\n",
       "   'lit',\n",
       "   'liv',\n",
       "   'liz',\n",
       "   'loa',\n",
       "   'lob',\n",
       "   'lod',\n",
       "   'lof',\n",
       "   'log',\n",
       "   'loo',\n",
       "   'lop',\n",
       "   'lot',\n",
       "   'lou',\n",
       "   'low',\n",
       "   'lox',\n",
       "   'loy',\n",
       "   'luc',\n",
       "   'lue',\n",
       "   'lug',\n",
       "   'lui',\n",
       "   'lum',\n",
       "   'luo',\n",
       "   'lur',\n",
       "   'lut',\n",
       "   'lux',\n",
       "   'lwo',\n",
       "   'lye',\n",
       "   'lys',\n",
       "   'mab',\n",
       "   'mac',\n",
       "   'mad',\n",
       "   'mae',\n",
       "   'mag',\n",
       "   'mah',\n",
       "   'mal',\n",
       "   'mam',\n",
       "   'man',\n",
       "   'mao',\n",
       "   'map',\n",
       "   'mar',\n",
       "   'mas',\n",
       "   'mat',\n",
       "   'mau',\n",
       "   'maw',\n",
       "   'max',\n",
       "   'may',\n",
       "   'meg',\n",
       "   'mel',\n",
       "   'mem',\n",
       "   'men',\n",
       "   'meo',\n",
       "   'mer',\n",
       "   'mes',\n",
       "   'met',\n",
       "   'mev',\n",
       "   'mew',\n",
       "   'mho',\n",
       "   'mib',\n",
       "   'mid',\n",
       "   'mig',\n",
       "   'mil',\n",
       "   'mim',\n",
       "   'min',\n",
       "   'mir',\n",
       "   'mix',\n",
       "   'mob',\n",
       "   'mod',\n",
       "   'moe',\n",
       "   'mog',\n",
       "   'moi',\n",
       "   'mon',\n",
       "   'moo',\n",
       "   'mop',\n",
       "   'mor',\n",
       "   'mot',\n",
       "   'mou',\n",
       "   'mow',\n",
       "   'moy',\n",
       "   'mrs',\n",
       "   'mru',\n",
       "   'mud',\n",
       "   'mug',\n",
       "   'mum',\n",
       "   'mun',\n",
       "   'mus',\n",
       "   'mux',\n",
       "   'mwa',\n",
       "   'mya',\n",
       "   'naa',\n",
       "   'nab',\n",
       "   'nae',\n",
       "   'nag',\n",
       "   'nak',\n",
       "   'nam',\n",
       "   'nan',\n",
       "   'nap',\n",
       "   'nar',\n",
       "   'nat',\n",
       "   'naw',\n",
       "   'nay',\n",
       "   'nea',\n",
       "   'neb',\n",
       "   'ned',\n",
       "   'nee',\n",
       "   'nef',\n",
       "   'nei',\n",
       "   'neo',\n",
       "   'nep',\n",
       "   'net',\n",
       "   'new',\n",
       "   'nib',\n",
       "   'nid',\n",
       "   'nig',\n",
       "   'nil',\n",
       "   'nim',\n",
       "   'nip',\n",
       "   'nit',\n",
       "   'nix',\n",
       "   'noa',\n",
       "   'nob',\n",
       "   'nod',\n",
       "   'nog',\n",
       "   'non',\n",
       "   'nor',\n",
       "   'not',\n",
       "   'nou',\n",
       "   'now',\n",
       "   'noy',\n",
       "   'nth',\n",
       "   'nub',\n",
       "   'nul',\n",
       "   'nun',\n",
       "   'nut',\n",
       "   'nye',\n",
       "   'oaf',\n",
       "   'oak',\n",
       "   'oam',\n",
       "   'oar',\n",
       "   'oat',\n",
       "   'obe',\n",
       "   'obi',\n",
       "   'och',\n",
       "   'ock',\n",
       "   'oda',\n",
       "   'odd',\n",
       "   'ode',\n",
       "   'ods',\n",
       "   'odz',\n",
       "   'oer',\n",
       "   'oes',\n",
       "   'off',\n",
       "   'ofo',\n",
       "   'oft',\n",
       "   'ohm',\n",
       "   'oho',\n",
       "   'oii',\n",
       "   'oil',\n",
       "   'oka',\n",
       "   'oki',\n",
       "   'old',\n",
       "   'ole',\n",
       "   'olm',\n",
       "   'ona',\n",
       "   'one',\n",
       "   'ons',\n",
       "   'ope',\n",
       "   'opt',\n",
       "   'ora',\n",
       "   'orb',\n",
       "   'orc',\n",
       "   'ore',\n",
       "   'orf',\n",
       "   'ort',\n",
       "   'ory',\n",
       "   'osc',\n",
       "   'ose',\n",
       "   'oto',\n",
       "   'ouf',\n",
       "   'our',\n",
       "   'out',\n",
       "   'ova',\n",
       "   'owd',\n",
       "   'owe',\n",
       "   'owk',\n",
       "   'owl',\n",
       "   'own',\n",
       "   'oxy',\n",
       "   'pac',\n",
       "   'pad',\n",
       "   'pah',\n",
       "   'pal',\n",
       "   'pam',\n",
       "   'pan',\n",
       "   'pap',\n",
       "   'par',\n",
       "   'pat',\n",
       "   'pau',\n",
       "   'paw',\n",
       "   'pax',\n",
       "   'pay',\n",
       "   'pea',\n",
       "   'ped',\n",
       "   'pee',\n",
       "   'peg',\n",
       "   'pen',\n",
       "   'pep',\n",
       "   'per',\n",
       "   'pes',\n",
       "   'pet',\n",
       "   'pew',\n",
       "   'phi',\n",
       "   'pho',\n",
       "   'phu',\n",
       "   'pia',\n",
       "   'pic',\n",
       "   'pie',\n",
       "   'pig',\n",
       "   'pik',\n",
       "   'pim',\n",
       "   'pin',\n",
       "   'pip',\n",
       "   'pir',\n",
       "   'pit',\n",
       "   'pix',\n",
       "   'ply',\n",
       "   'poa',\n",
       "   'pob',\n",
       "   'pod',\n",
       "   'poe',\n",
       "   'poh',\n",
       "   'poi',\n",
       "   'pol',\n",
       "   'pom',\n",
       "   'pon',\n",
       "   'pop',\n",
       "   'pot',\n",
       "   'pow',\n",
       "   'pox',\n",
       "   'poy',\n",
       "   'pro',\n",
       "   'pry',\n",
       "   'psi',\n",
       "   'pst',\n",
       "   'pua',\n",
       "   'pub',\n",
       "   'pud',\n",
       "   'pug',\n",
       "   'pul',\n",
       "   'pun',\n",
       "   'pup',\n",
       "   'pur',\n",
       "   'pus',\n",
       "   'put',\n",
       "   'pya',\n",
       "   'pyr',\n",
       "   'pyx',\n",
       "   'qua',\n",
       "   'quo',\n",
       "   'rab',\n",
       "   'rad',\n",
       "   'rag',\n",
       "   'rah',\n",
       "   'raj',\n",
       "   'ram',\n",
       "   'ran',\n",
       "   'rap',\n",
       "   'ras',\n",
       "   'rat',\n",
       "   'raw',\n",
       "   'rax',\n",
       "   'ray',\n",
       "   'rea',\n",
       "   'reb',\n",
       "   'red',\n",
       "   'ree',\n",
       "   'ref',\n",
       "   'reg',\n",
       "   'reh',\n",
       "   'rel',\n",
       "   'rep',\n",
       "   'ret',\n",
       "   'rev',\n",
       "   'rex',\n",
       "   'rhe',\n",
       "   'rho',\n",
       "   'ria',\n",
       "   'rib',\n",
       "   'ric',\n",
       "   'rid',\n",
       "   'rie',\n",
       "   'rig',\n",
       "   'rik',\n",
       "   'rim',\n",
       "   'rio',\n",
       "   'rip',\n",
       "   'rit',\n",
       "   'rix',\n",
       "   'rob',\n",
       "   'roc',\n",
       "   'rod',\n",
       "   'roe',\n",
       "   'rog',\n",
       "   'roi',\n",
       "   'rok',\n",
       "   'ron',\n",
       "   'rot',\n",
       "   'row',\n",
       "   'rox',\n",
       "   'roy',\n",
       "   'rua',\n",
       "   'rub',\n",
       "   'rud',\n",
       "   'rue',\n",
       "   'rug',\n",
       "   'rum',\n",
       "   'run',\n",
       "   'rus',\n",
       "   'rut',\n",
       "   'rux',\n",
       "   'rye',\n",
       "   'saa',\n",
       "   'sab',\n",
       "   'sac',\n",
       "   'sad',\n",
       "   'sag',\n",
       "   'sah',\n",
       "   'sai',\n",
       "   'saj',\n",
       "   'sak',\n",
       "   'sal',\n",
       "   'sam',\n",
       "   'san',\n",
       "   'sao',\n",
       "   'sap',\n",
       "   'sar',\n",
       "   'sat',\n",
       "   'saw',\n",
       "   'sax',\n",
       "   'say',\n",
       "   'sea',\n",
       "   'sec',\n",
       "   'see',\n",
       "   'seg',\n",
       "   'sen',\n",
       "   'ser',\n",
       "   'set',\n",
       "   'sew',\n",
       "   'sex',\n",
       "   'sey',\n",
       "   'sha',\n",
       "   'she',\n",
       "   'shi',\n",
       "   'sho',\n",
       "   'shu',\n",
       "   'shy',\n",
       "   'sia',\n",
       "   'sib',\n",
       "   'sic',\n",
       "   'sid',\n",
       "   'sie',\n",
       "   'sig',\n",
       "   'sil',\n",
       "   'sim',\n",
       "   'sin',\n",
       "   'sip',\n",
       "   'sir',\n",
       "   'sis',\n",
       "   'sit',\n",
       "   'six',\n",
       "   'ski',\n",
       "   'sky',\n",
       "   'sla',\n",
       "   ...])]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(len_dict.items())[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['formaldehydesulphoxylate',\n",
       " 'pathologicopsychological',\n",
       " 'scientificophilosophical',\n",
       " 'tetraiodophenolphthalein',\n",
       " 'thyroparathyroidectomize']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_dict[24]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm appears to have worked. That is, the words are organized by length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigs_by_len = {}\n",
    "for key, word_list in len_dict.items():\n",
    "    sigs_by_len[key] = {word: anagram_fast(word) for word in word_list if len(anagram_fast(word)) > 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sigs_by_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "{'anatomicopathologic': ['anatomicopathologic', 'pathologicoanatomic'], 'clinicopathological': ['clinicopathological', 'pathologicoclinical'], 'encephalomeningitis': ['encephalomeningitis', 'meningoencephalitis'], 'esophagogastrostomy': ['esophagogastrostomy', 'gastroesophagostomy'], 'gastroesophagostomy': ['esophagogastrostomy', 'gastroesophagostomy'], 'incontrovertibility': ['incontrovertibility', 'introconvertibility'], 'introconvertibility': ['incontrovertibility', 'introconvertibility'], 'meningoencephalitis': ['encephalomeningitis', 'meningoencephalitis'], 'pathologicoanatomic': ['anatomicopathologic', 'pathologicoanatomic'], 'pathologicoclinical': ['clinicopathological', 'pathologicoclinical'], 'pericardiacophrenic': ['pericardiacophrenic', 'phrenicopericardiac'], 'phrenicopericardiac': ['pericardiacophrenic', 'phrenicopericardiac'], 'physiopsychological': ['physiopsychological', 'psychophysiological'], 'psychophysiological': ['physiopsychological', 'psychophysiological']}\n"
     ]
    }
   ],
   "source": [
    "for x in list(sigs_by_len.items())[16]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the dictionary has created a list of anagrams for each word in the length key. We want to take the length of each list, minus 1 because we don't want to include the word itself in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "anagram_lens = {}\n",
    "for key, word_list in len_dict.items():\n",
    "    anagram_lens[key] = {word: len(anagram_fast(word)) - 1 for word in word_list if len(anagram_fast(word)) > 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "{'anatomicopathologic': 1, 'clinicopathological': 1, 'encephalomeningitis': 1, 'esophagogastrostomy': 1, 'gastroesophagostomy': 1, 'incontrovertibility': 1, 'introconvertibility': 1, 'meningoencephalitis': 1, 'pathologicoanatomic': 1, 'pathologicoclinical': 1, 'pericardiacophrenic': 1, 'phrenicopericardiac': 1, 'physiopsychological': 1, 'psychophysiological': 1}\n"
     ]
    }
   ],
   "source": [
    "for x in list(anagram_lens.items())[16]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to sum all of the results in each length key. We should also divide the results by two to prevent double counting (elvis and lives would be counted once for elvis and once for lives)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "anagram_lens = {}\n",
    "for key, word_list in len_dict.items():\n",
    "    anagram_lens[key] = sum(len(anagram_fast(word)) - 1 for word in word_list if len(anagram_fast(word)) > 1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.0,\n",
       " 2: 40.0,\n",
       " 3: 554.0,\n",
       " 5: 4247.0,\n",
       " 4: 2780.0,\n",
       " 8: 3097.0,\n",
       " 7: 4220.0,\n",
       " 9: 2100.0,\n",
       " 6: 5153.0,\n",
       " 11: 584.0,\n",
       " 10: 1168.0,\n",
       " 12: 288.0,\n",
       " 14: 70.0,\n",
       " 16: 35.0,\n",
       " 15: 49.0,\n",
       " 20: 3.0,\n",
       " 19: 7.0,\n",
       " 17: 22.0,\n",
       " 13: 137.0,\n",
       " 18: 10.0,\n",
       " 21: 4.0,\n",
       " 22: 2.0,\n",
       " 23: 0.0,\n",
       " 24: 0.0}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anagram_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pfds",
   "language": "python",
   "name": "pfds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
